# üìù TODO

- [ ] [Bordes, An Introduction to Vision-Language Modelling](obsidian://open?vault=research-vault&file=articles%2FAn-Introduction-to-Vision-Language-Modelling_Meta-AI.pdf)
- [ ] [Xu, Vision and Language Navigation in the Real World via Online Visual Language Mapping](obsidian://open?vault=research-vault&file=articles%2FOnline-Vision-Language-Mapping.pdf)
- [ ] [Yokoyama, VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation](obsidian://open?vault=research-vault&file=articles%2FVLFM-Zero-Shot-Semantic-Navigation.pdf)
- [ ] [Lian, DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking](obsidian://open?vault=research-vault&file=articles%2FDORT-Multi-Cam-3D-Object-Detection-and-Tracking.pdf)
- [ ] [Huang, Audio Visual Language Maps for Robot Navigation](obsidian://open?vault=research-vault&file=articles%2FAudio-Visual-Language-Maps.pdf)
- [ ] [LabelFormer: Object Trajectory ReÔ¨Ånement for Offboard Perception from LiDAR Point Clouds](https://openreview.net/pdf?id=9cTEQWMo1BF)
- [x] [Dosovitskiy, An Image is Worth 16x16 Words (Vision Transformers)](obsidian://open?vault=research-vault&file=articles%2FVision-Transformers.pdf)
- [x] [Vaswani, Attention is All You Need](obsidian://open?vault=research-vault&file=articles%2FAttention-Is-All-You-Need_Google-Brain.pdf)
