# üìù TODO

- [ ] [Bordes, An Introduction to Vision-Language Modelling](obsidian://open?vault=research-vault&file=articles%2FAn-Introduction-to-Vision-Language-Modelling_Meta-AI.pdf)
- [ ] [Xu, Vision and Language Navigation in the Real World via Online Visual Language Mapping](obsidian://open?vault=research-vault&file=articles%2FOnline-Vision-Language-Mapping.pdf)
- [x] [Yokoyama, VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation](obsidian://open?vault=research-vault&file=articles%2FVLFM-Zero-Shot-Semantic-Navigation.pdf)
- [ ] [Lian, DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking](obsidian://open?vault=research-vault&file=articles%2FDORT-Multi-Cam-3D-Object-Detection-and-Tracking.pdf)
- [ ] [Huang, Audio Visual Language Maps for Robot Navigation](obsidian://open?vault=research-vault&file=articles%2FAudio-Visual-Language-Maps.pdf)
- [ ] [[bs-thesis/articles/Vision-Language-maps-for-Robot-Navigation.pdf|Huang et al., Vision Language Maps for Robot Navigation]]
- [ ] [LabelFormer: Object Trajectory ReÔ¨Ånement for Offboard Perception from LiDAR Point Clouds](https://openreview.net/pdf?id=9cTEQWMo1BF)
- [x] [Dosovitskiy, An Image is Worth 16x16 Words (Vision Transformers)](obsidian://open?vault=research-vault&file=articles%2FVision-Transformers.pdf)
- [x] [Vaswani, Attention is All You Need](obsidian://open?vault=research-vault&file=articles%2FAttention-Is-All-You-Need_Google-Brain.pdf)

# :rif_file_paper: Find More

- [:rif_github:/eric-ai-lab/awesome-vision-language-navigation](https://github.com/eric-ai-lab/awesome-vision-language-navigation)
- [:rif_github:/jingyi0000/VLM_survey](https://github.com/jingyi0000/VLM_survey)
- [:rif_github:/sangminwoo/awesome-vision-and-language#vision-and-language-navigation](https://github.com/sangminwoo/awesome-vision-and-language?tab=readme-ov-file#vision-and-language-navigation)
- [:rif_github:/ryanbgriffiths/ICRA2023PaperList](https://github.com/ryanbgriffiths/ICRA2023PaperList)
